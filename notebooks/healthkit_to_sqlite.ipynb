{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database - functions for data back-end / manipulations\n",
    "\n",
    "This is using an alternate approach:\n",
    "  - Export all of my Apple HealthFit data from the Health app to export.zip \n",
    "  - Converted this to a SQLite database using `healthfit-to-sqlite`\n",
    "  - Run various SQL queries to allow for producing a summary of (walk/hike) workouts\n",
    " \n",
    "  Queries can then against this database to build the cache file (or possibly a smaller custom SQLite file) as input into the walk mapping app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import pendulum\n",
    "from sqlite_utils import Database\n",
    "import reverse_geocoder as rg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting HealthKit data / creating SQLite DB\n",
    "\n",
    "First export HealthKit data using the Health app - select your profile icon from the top-right of the main screen and then select **Export All Health Data** (this can take some time to create the `export.zip` file).\n",
    "\n",
    "The archive can be converted to a SQLite database using the following command:\n",
    "\n",
    "`healthkit-to-sqlite export.zip healthkit_db.sqlite`\n",
    "\n",
    "which requires the `healthkit-to-sqlite` library to be installed (note it is one of the requirements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEALTHKIT_DATA_PATH = \"/Users/mjboothaus/icloud/Data/apple_health_export\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mapple_health_export_11Mar2023\u001b[m\u001b[m export_2022_09_19.zip\n",
      "export 2.zip                  export_2022_12_30.zip\n",
      "export.zip                    export_2023_03_11.zip\n",
      "export_15May2023.zip\n"
     ]
    }
   ],
   "source": [
    "!ls $HEALTHKIT_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_zip = Path(HEALTHKIT_DATA_PATH) / \"export_23May2023.zip\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_zip.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_zip.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(latitude, longitude):\n",
    "    location = rg.search((latitude, longitude))\n",
    "    return [location[0][\"name\"], location[0][\"admin1\"], location[0][\"cc\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_elapsed_time_minutes(finish_datetime, start_datetime):\n",
    "    dt = pendulum.parse(finish_datetime) - pendulum.parse(start_datetime)\n",
    "    return float(dt.in_seconds() / 60 / 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_healthkit_export_to_sqlite(export_zip):\n",
    "    zip_file = export_zip.as_posix()\n",
    "    if not export_zip.exists():\n",
    "        print(zip_file, \": not found\")\n",
    "        return None, f\"{zip_file}: not found\"\n",
    "    zip_file_date = pendulum.instance(\n",
    "        dt.datetime.fromtimestamp(export_zip.stat().st_ctime)\n",
    "    )\n",
    "\n",
    "    db_file = zip_file.replace(\"export.zip\", \"healthkit_db.sqlite\")\n",
    "    if Path(db_file).exists() is True:\n",
    "        Path(db_file).unlink()\n",
    "    sp_cmd = f\"healthkit-to-sqlite {zip_file} {db_file}\"\n",
    "\n",
    "    sp = subprocess.Popen(sp_cmd, stdout=subprocess.PIPE, shell=True)\n",
    "    (sp_output, _) = sp.communicate()\n",
    "\n",
    "    # This makes the wait possible\n",
    "    # sp_status = sp.wait()\n",
    "\n",
    "    db_file_with_date = db_file.replace(\n",
    "        \".sqlite\", \"_\" + zip_file_date.to_date_string().replace(\"-\", \"_\") + \".sqlite\"\n",
    "    )\n",
    "\n",
    "    export_zip.rename(\n",
    "        zip_file.replace(\n",
    "            \".zip\", \"_\" + zip_file_date.to_date_string().replace(\"-\", \"_\") + \".zip\"\n",
    "        )\n",
    "    )\n",
    "    Path(db_file).rename(db_file_with_date)\n",
    "\n",
    "    return db_file_with_date, sp_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_sql_query_in_file(\n",
    "    filename_dot_sql, conn, parse_dates, echo_query=False\n",
    "):\n",
    "\n",
    "    query_file = Path.cwd().parent / \"sql\" / filename_dot_sql\n",
    "\n",
    "    with open(query_file, \"r\") as query:\n",
    "        sql_text = query.read()\n",
    "        if echo_query is True:\n",
    "            print(sql_text)\n",
    "        df = pd.read_sql_query(sql_text, conn, parse_dates=parse_dates)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_walk_workout_summary(\n",
    "    db_file, output_file=\"../data/workouts_summary.csv\", include_location=False\n",
    "):\n",
    "    if db_file is None or Path(db_file).exists() is False:\n",
    "        print(\"SQLite database doesn't exist or not found\")\n",
    "        return None\n",
    "    db = Database(db_file)\n",
    "\n",
    "    # Extract data\n",
    "\n",
    "    workouts_df = create_df_from_sql_query_in_file(\n",
    "        \"select_star_walking_workouts.sql\", db.conn, [\"startDate\", \"endDate\"]\n",
    "    )\n",
    "    start_point_df = create_df_from_sql_query_in_file(\n",
    "        \"select_start_point_workout.sql\", db.conn, [\"date\"]\n",
    "    )\n",
    "    finish_point_df = create_df_from_sql_query_in_file(\n",
    "        \"select_finish_point_workout.sql\", db.conn, [\"date\"]\n",
    "    )\n",
    "\n",
    "    # Perform joins and additional column manipulations\n",
    "\n",
    "    workouts_df[\"startDate\"] = workouts_df[\"startDate\"].apply(\n",
    "        lambda dt: pendulum.instance(dt).to_datetime_string()\n",
    "    )\n",
    "    workouts_df[\"endDate\"] = workouts_df[\"endDate\"].apply(\n",
    "        lambda dt: pendulum.instance(dt).to_datetime_string()\n",
    "    )\n",
    "    workouts_summary_df = start_point_df.merge(\n",
    "        finish_point_df, how=\"inner\", on=\"workout_id\"\n",
    "    )\n",
    "    workouts_summary_df[\"elapsed_time_hours\"] = workouts_summary_df.apply(\n",
    "        lambda row: calculate_elapsed_time_minutes(\n",
    "            row[\"finish_datetime\"], row[\"start_datetime\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    workouts_summary_df[\"start_datetime\"] = workouts_summary_df[\"start_datetime\"].apply(\n",
    "        lambda dt: pendulum.parse(dt, tz=\"Australia/Sydney\").to_datetime_string()\n",
    "    )\n",
    "\n",
    "    if include_location is True:\n",
    "        workouts_summary_df[\"start_location\"] = workouts_summary_df.apply(\n",
    "            lambda row: get_location(\n",
    "                float(row[\"start_latitude\"]), float(row[\"start_longitude\"])\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        workouts_summary_df[\"finish_location\"] = workouts_summary_df.apply(\n",
    "            lambda row: get_location(\n",
    "                float(row[\"finish_latitude\"]), float(row[\"finish_longitude\"])\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "    workouts_summary_df = workouts_summary_df.merge(\n",
    "        workouts_df, how=\"inner\", on=\"workout_id\"\n",
    "    )\n",
    "\n",
    "    workouts_summary_df.to_csv(output_file, index=False)\n",
    "    return Path(output_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_convert_create_walk_summary(path_export_zip, include_location=False):\n",
    "    db_file, _ = convert_healthkit_export_to_sqlite(path_export_zip)\n",
    "    output_file = create_walk_workout_summary(db_file, include_location=include_location)\n",
    "    return db_file, output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: healthkit-to-sqlite [OPTIONS] EXPORT_ZIP DB_PATH\n",
      "Try 'healthkit-to-sqlite --help' for help.\n",
      "\n",
      "Error: Invalid value for 'EXPORT_ZIP': File '/Users/mjboothaus/icloud/Data/apple_health_export/export_23May2023.zip' does not exist.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/mjboothaus/icloud/Data/apple_health_export/export_23May2023.zip' -> '/Users/mjboothaus/icloud/Data/apple_health_export/export_23May2023_2023_05_23.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m db_file, output_file \u001b[39m=\u001b[39m main_convert_create_walk_summary(export_zip, include_location\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m, in \u001b[0;36mmain_convert_create_walk_summary\u001b[0;34m(path_export_zip, include_location)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain_convert_create_walk_summary\u001b[39m(path_export_zip, include_location\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m----> 2\u001b[0m     db_file, _ \u001b[39m=\u001b[39m convert_healthkit_export_to_sqlite(path_export_zip)\n\u001b[1;32m      3\u001b[0m     output_file \u001b[39m=\u001b[39m create_walk_workout_summary(db_file, include_location\u001b[39m=\u001b[39minclude_location)\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m db_file, output_file\n",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m, in \u001b[0;36mconvert_healthkit_export_to_sqlite\u001b[0;34m(export_zip)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m# This makes the wait possible\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m# sp_status = sp.wait()\u001b[39;00m\n\u001b[1;32m     21\u001b[0m db_file_with_date \u001b[39m=\u001b[39m db_file\u001b[39m.\u001b[39mreplace(\n\u001b[1;32m     22\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m.sqlite\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m zip_file_date\u001b[39m.\u001b[39mto_date_string()\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.sqlite\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m export_zip\u001b[39m.\u001b[39;49mrename(\n\u001b[1;32m     26\u001b[0m     zip_file\u001b[39m.\u001b[39;49mreplace(\n\u001b[1;32m     27\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m.zip\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m zip_file_date\u001b[39m.\u001b[39;49mto_date_string()\u001b[39m.\u001b[39;49mreplace(\u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.zip\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m Path(db_file)\u001b[39m.\u001b[39mrename(db_file_with_date)\n\u001b[1;32m     32\u001b[0m \u001b[39mreturn\u001b[39;00m db_file_with_date, sp_output\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/pathlib.py:1382\u001b[0m, in \u001b[0;36mPath.rename\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrename\u001b[39m(\u001b[39mself\u001b[39m, target):\n\u001b[1;32m   1373\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1374\u001b[0m \u001b[39m    Rename this path to the target path.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[39m    Returns the new Path instance pointing to the target path.\u001b[39;00m\n\u001b[1;32m   1381\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1382\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mrename(\u001b[39mself\u001b[39;49m, target)\n\u001b[1;32m   1383\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(target)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mjboothaus/icloud/Data/apple_health_export/export_23May2023.zip' -> '/Users/mjboothaus/icloud/Data/apple_health_export/export_23May2023_2023_05_23.zip'"
     ]
    }
   ],
   "source": [
    "db_file, output_file = main_convert_create_walk_summary(export_zip, include_location=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_walk_stats(walk_data):\n",
    "    total_time = dt.timedelta(0)\n",
    "    total_distance = 0\n",
    "\n",
    "    for hike in walk_data:\n",
    "        total_time += hike.index.max()\n",
    "        # print(iHike+1, walk_date[iHike], hike.index.max(), hike['dist'].max() / 1e3)\n",
    "        total_distance += hike[\"dist\"].max()\n",
    "    total_distance /= 1e3\n",
    "\n",
    "    start_coord = walk_data[0][[\"lat\", \"lon\"]].iloc[0].tolist()\n",
    "    end_coord = walk_data[-1][[\"lat\", \"lon\"]].iloc[-1].tolist()\n",
    "    return total_time, total_distance, start_coord, end_coord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_walk_cached_data_for_app(db_file, n_rows_used=5):\n",
    "    # read in all of the walks data and sample at an appropriate frequency and cache for faster use in the app\n",
    "    db = Database(db_file)\n",
    "    walk_df = pd.read_sql_query(\"SELECT * FROM walks\", db.conn)\n",
    "\n",
    "    UNUSED_COLUMNS = [\"dist\", \"speed\"]\n",
    "\n",
    "    walk_df.drop(UNUSED_COLUMNS, axis=1, inplace=True)\n",
    "    walk_df.dropna(inplace=True)  # TODO: Check why there are a few NaNs\n",
    "    walk_df = walk_df.iloc[::n_rows_used].reset_index()  # downsample\n",
    "\n",
    "    walk_df.to_feather(Path(db_file.as_posix().replace(\".db\", \".cache.feather\")))\n",
    "\n",
    "    return walk_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "a53a55b0073614e9e0c431f4185a85688d811cf9f818579d72a21abdfe61484e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
