{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database - functions for data back-end / manipulations\n",
    "\n",
    "This is using an alternate approach:\n",
    "  - Export all of my Apple HealthFit data from the Health app to export.zip \n",
    "  - Converted this to a SQLite database using `healthfit-to-sqlite`\n",
    "  - Run various SQL queries to allow for producing a summary of (walk/hike) workouts\n",
    " \n",
    "  Queries can then against this database to build the cache file (or possibly a smaller custom SQLite file) as input into the walk mapping app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import pendulum\n",
    "from sqlite_utils import Database\n",
    "import reverse_geocoder as rg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting HealthKit data / creating SQLite DB\n",
    "\n",
    "First export HealthKit data using the Health app - select your profile icon from the top-right of the main screen and then select **Export All Health Data** (this can take some time to create the `export.zip` file).\n",
    "\n",
    "The archive can be converted to a SQLite database using the following command:\n",
    "\n",
    "`healthkit-to-sqlite export.zip healthkit_db.sqlite`\n",
    "\n",
    "which requires the `healthkit-to-sqlite` library to be installed (note it is one of the requirements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEALTHKIT_DATA_PATH = \"/Users/mjboothaus/icloud/Data/apple_health_export\"\n",
    "export_zip = Path(HEALTHKIT_DATA_PATH) / \"export.zip\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(latitude, longitude):\n",
    "    location = rg.search((latitude, longitude))\n",
    "    return [location[0][\"name\"], location[0][\"admin1\"], location[0][\"cc\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_elapsed_time_minutes(finish_datetime, start_datetime):\n",
    "    dt = pendulum.parse(finish_datetime) - pendulum.parse(start_datetime)\n",
    "    return float(dt.in_seconds() / 60 / 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_healthkit_export_to_sqlite(export_zip):\n",
    "    zip_file = export_zip.as_posix()\n",
    "    if export_zip.exists() is False:\n",
    "        print(zip_file, \": not found\")\n",
    "        return None, f\"{zip_file}: not found\"\n",
    "    zip_file_date = pendulum.instance(\n",
    "        dt.datetime.fromtimestamp(export_zip.stat().st_ctime)\n",
    "    )\n",
    "\n",
    "    db_file = zip_file.replace(\"export.zip\", \"healthkit_db.sqlite\")\n",
    "    if Path(db_file).exists() is True:\n",
    "        Path(db_file).unlink()\n",
    "    sp_cmd = f\"healthkit-to-sqlite {zip_file} {db_file}\"\n",
    "\n",
    "    sp = subprocess.Popen(sp_cmd, stdout=subprocess.PIPE, shell=True)\n",
    "    (sp_output, _) = sp.communicate()\n",
    "\n",
    "    # This makes the wait possible\n",
    "    # sp_status = sp.wait()\n",
    "\n",
    "    db_file_with_date = db_file.replace(\n",
    "        \".sqlite\", \"_\" + zip_file_date.to_date_string().replace(\"-\", \"_\") + \".sqlite\"\n",
    "    )\n",
    "\n",
    "    export_zip.rename(\n",
    "        zip_file.replace(\n",
    "            \".zip\", \"_\" + zip_file_date.to_date_string().replace(\"-\", \"_\") + \".zip\"\n",
    "        )\n",
    "    )\n",
    "    Path(db_file).rename(db_file_with_date)\n",
    "\n",
    "    return db_file_with_date, sp_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_sql_query_in_file(\n",
    "    filename_dot_sql, conn, parse_dates, echo_query=False\n",
    "):\n",
    "\n",
    "    query_file = Path.cwd().parent / \"sql\" / filename_dot_sql\n",
    "\n",
    "    with open(query_file, \"r\") as query:\n",
    "        sql_text = query.read()\n",
    "        if echo_query is True:\n",
    "            print(sql_text)\n",
    "        df = pd.read_sql_query(sql_text, conn, parse_dates=parse_dates)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_walk_workout_summary(\n",
    "    db_file, output_file=\"../data/workouts_summary.csv\", include_location=False\n",
    "):\n",
    "    if db_file is None or Path(db_file).exists() is False:\n",
    "        print(\"SQLite database doesn't exist or not found\")\n",
    "        return None\n",
    "    db = Database(db_file)\n",
    "\n",
    "    # Extract data\n",
    "\n",
    "    workouts_df = create_df_from_sql_query_in_file(\n",
    "        \"select_star_walking_workouts.sql\", db.conn, [\"startDate\", \"endDate\"]\n",
    "    )\n",
    "    start_point_df = create_df_from_sql_query_in_file(\n",
    "        \"select_start_point_workout.sql\", db.conn, [\"date\"]\n",
    "    )\n",
    "    finish_point_df = create_df_from_sql_query_in_file(\n",
    "        \"select_finish_point_workout.sql\", db.conn, [\"date\"]\n",
    "    )\n",
    "\n",
    "    # Perform joins and additional column manipulations\n",
    "\n",
    "    workouts_df[\"startDate\"] = workouts_df[\"startDate\"].apply(\n",
    "        lambda dt: pendulum.instance(dt).to_datetime_string()\n",
    "    )\n",
    "    workouts_df[\"endDate\"] = workouts_df[\"endDate\"].apply(\n",
    "        lambda dt: pendulum.instance(dt).to_datetime_string()\n",
    "    )\n",
    "    workouts_summary_df = start_point_df.merge(\n",
    "        finish_point_df, how=\"inner\", on=\"workout_id\"\n",
    "    )\n",
    "    workouts_summary_df[\"elapsed_time_hours\"] = workouts_summary_df.apply(\n",
    "        lambda row: calculate_elapsed_time_minutes(\n",
    "            row[\"finish_datetime\"], row[\"start_datetime\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    workouts_summary_df[\"start_datetime\"] = workouts_summary_df[\"start_datetime\"].apply(\n",
    "        lambda dt: pendulum.parse(dt, tz=\"Australia/Sydney\").to_datetime_string()\n",
    "    )\n",
    "\n",
    "    if include_location is True:\n",
    "        workouts_summary_df[\"start_location\"] = workouts_summary_df.apply(\n",
    "            lambda row: get_location(\n",
    "                float(row[\"start_latitude\"]), float(row[\"start_longitude\"])\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        workouts_summary_df[\"finish_location\"] = workouts_summary_df.apply(\n",
    "            lambda row: get_location(\n",
    "                float(row[\"finish_latitude\"]), float(row[\"finish_longitude\"])\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "    workouts_summary_df = workouts_summary_df.merge(\n",
    "        workouts_df, how=\"inner\", on=\"workout_id\"\n",
    "    )\n",
    "\n",
    "    workouts_summary_df.to_csv(output_file, index=False)\n",
    "    return Path(output_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_convert_create_walk_summary(path_export_zip, include_location=False):\n",
    "    db_file, _ = convert_healthkit_export_to_sqlite(path_export_zip)\n",
    "    output_file = create_walk_workout_summary(db_file, include_location=include_location)\n",
    "    return db_file, output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file, output_file = main_convert_create_walk_summary(export_zip, include_location=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mjboothaus/icloud/Data/apple_health_export/healthkit_db_2022_05_30.sqlite'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/workouts_summary.xlsx')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_walk_stats(walk_data):\n",
    "    total_time = dt.timedelta(0)\n",
    "    total_distance = 0\n",
    "\n",
    "    for hike in walk_data:\n",
    "        total_time += hike.index.max()\n",
    "        # print(iHike+1, walk_date[iHike], hike.index.max(), hike['dist'].max() / 1e3)\n",
    "        total_distance += hike[\"dist\"].max()\n",
    "    total_distance /= 1e3\n",
    "\n",
    "    start_coord = walk_data[0][[\"lat\", \"lon\"]].iloc[0].tolist()\n",
    "    end_coord = walk_data[-1][[\"lat\", \"lon\"]].iloc[-1].tolist()\n",
    "    return total_time, total_distance, start_coord, end_coord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_walk_cached_data_for_app(db_file, n_rows_used=5):\n",
    "    # read in all of the walks data and sample at an appropriate frequency and cache for faster use in the app\n",
    "    db = Database(db_file)\n",
    "    walk_df = pd.read_sql_query(\"SELECT * FROM walks\", db.conn)\n",
    "\n",
    "    UNUSED_COLUMNS = [\"dist\", \"speed\"]\n",
    "\n",
    "    walk_df.drop(UNUSED_COLUMNS, axis=1, inplace=True)\n",
    "    walk_df.dropna(inplace=True)  # TODO: Check why there are a few NaNs\n",
    "    walk_df = walk_df.iloc[::n_rows_used].reset_index()  # downsample\n",
    "\n",
    "    walk_df.to_feather(Path(db_file.as_posix().replace(\".db\", \".cache.feather\")))\n",
    "\n",
    "    return walk_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv_dev_emmaus-walking-data': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "16f5e3a5bb0f231f1f5d5bd0bebf4d5ec22b5133b248f5356db34e08ee78fc16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
